fastapi==0.115.0
uvicorn[standard]==0.30.5
llama-cpp-python==0.3.2
gradio==5